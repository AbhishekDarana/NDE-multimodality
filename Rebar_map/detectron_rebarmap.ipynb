{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Author-Abhishek Darana - 07/18/2024 - I have tried building a model using detectron2. Built-in evaluation metrics are failing due single point masks have to fix that\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to load COCO formatted dataset with absolute paths\n",
    "def load_coco_json(json_file):\n",
    "    with open(json_file) as f:\n",
    "        coco_dict = json.load(f)\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for image_info in coco_dict[\"images\"]:\n",
    "        record = {}\n",
    "        record[\"file_name\"] = image_info[\"file_name\"]  # Absolute path to the image\n",
    "        record[\"image_id\"] = image_info[\"id\"]\n",
    "        record[\"height\"] = image_info[\"height\"]\n",
    "        record[\"width\"] = image_info[\"width\"]\n",
    "\n",
    "        annos = [anno for anno in coco_dict[\"annotations\"] if anno[\"image_id\"] == image_info[\"id\"]]\n",
    "        objs = []\n",
    "        for anno in annos:\n",
    "            obj = {\n",
    "                \"bbox\": anno[\"bbox\"],\n",
    "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                \"category_id\": anno[\"category_id\"],\n",
    "                \"segmentation\": anno.get(\"segmentation\"),\n",
    "                \"iscrowd\": anno.get(\"iscrowd\", 0)\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    \n",
    "    return dataset_dicts\n",
    "\n",
    "# Paths to your JSON file\n",
    "json_file = os.path.join(\"C:\\\\Users\\\\Abhishek\\\\Documents\\\\Summer_research\\\\CHARISMA-main\\\\ground-penetrating-radar\\\\Rebar mapping\\\\code\\\\COCO_scripts\\\\coco_dataset_0.json\")#\"C:\\\\Users\\\\Abhishek\\\\Documents\\\\Summer_research\\\\CHARISMA-main\\\\ground-penetrating-radar\\\\Rebar mapping\\\\code\\\\coco_dataset.json\")\n",
    "\n",
    "dataset_dicts = load_coco_json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset_dicts)\n",
    "split_index = int(0.8 * len(dataset_dicts))  # 80% for training, 20% for validation\n",
    "train_dataset_dicts = dataset_dicts[:split_index]\n",
    "val_dataset_dicts = dataset_dicts[split_index:]\n",
    "\n",
    "# Register the dataset\n",
    "def register_dataset(dataset_dicts, name):\n",
    "    DatasetCatalog.register(name, lambda: dataset_dicts)\n",
    "    MetadataCatalog.get(name).set(thing_classes=[\"Rebar\"])\n",
    "\n",
    "register_dataset(train_dataset_dicts, \"my_dataset_train\")\n",
    "register_dataset(val_dataset_dicts, \"my_dataset_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/17 19:07:59 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[07/17 19:07:59 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 13 images left.\n",
      "\u001b[32m[07/17 19:07:59 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   Rebar    | 143          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[07/17 19:07:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/17 19:07:59 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/17 19:07:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/17 19:07:59 d2.data.common]: \u001b[0mSerializing 13 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/17 19:07:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[07/17 19:07:59 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[07/17 19:07:59 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/17 19:07:59 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abhishek\\anaconda3\\envs\\detectron2_env\\Lib\\site-packages\\torch\\functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3588.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/17 19:13:32 d2.utils.events]: \u001b[0m eta: 0:37:27  iter: 19  total_loss: 0.648  loss_cls: 0.6446  loss_box_reg: 0  loss_rpn_cls: 0.02089  loss_rpn_loc: 0    time: 16.1605  last_time: 16.4508  data_time: 0.3325  last_data_time: 0.0038   lr: 2.9908e-05  \n",
      "\u001b[32m[07/17 19:19:08 d2.utils.events]: \u001b[0m eta: 0:33:05  iter: 39  total_loss: 0.2757  loss_cls: 0.2483  loss_box_reg: 0  loss_rpn_cls: 0.02001  loss_rpn_loc: 0    time: 16.4743  last_time: 18.9550  data_time: 0.0038  last_data_time: 0.0041   lr: 6.1127e-05  \n",
      "\u001b[32m[07/17 19:24:39 d2.utils.events]: \u001b[0m eta: 0:27:34  iter: 59  total_loss: 0.06598  loss_cls: 0.05423  loss_box_reg: 0  loss_rpn_cls: 0.01043  loss_rpn_loc: 0    time: 16.5123  last_time: 14.5268  data_time: 0.0037  last_data_time: 0.0030   lr: 9.2345e-05  \n",
      "\u001b[32m[07/17 19:30:23 d2.utils.events]: \u001b[0m eta: 0:22:19  iter: 79  total_loss: 0.0215  loss_cls: 0.01885  loss_box_reg: 0  loss_rpn_cls: 0.0001484  loss_rpn_loc: 0    time: 16.6867  last_time: 14.7854  data_time: 0.0036  last_data_time: 0.0032   lr: 0.00012356  \n",
      "\u001b[32m[07/17 19:35:46 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 99  total_loss: 0.01077  loss_cls: 0.009904  loss_box_reg: 0  loss_rpn_cls: 7.16e-05  loss_rpn_loc: 0    time: 16.5750  last_time: 18.2312  data_time: 0.0040  last_data_time: 0.0050   lr: 0.00015478  \n",
      "\u001b[32m[07/17 19:41:40 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 119  total_loss: 0.006363  loss_cls: 0.005999  loss_box_reg: 0  loss_rpn_cls: 2.736e-05  loss_rpn_loc: 0    time: 16.7640  last_time: 20.2385  data_time: 0.0035  last_data_time: 0.0048   lr: 0.000186  \n",
      "\u001b[32m[07/17 19:47:24 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 139  total_loss: 0.00401  loss_cls: 0.003837  loss_box_reg: 0  loss_rpn_cls: 4.786e-05  loss_rpn_loc: 0    time: 16.8274  last_time: 17.1908  data_time: 0.0032  last_data_time: 0.0045   lr: 0.00021722  \n",
      "\u001b[32m[07/17 19:53:37 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 159  total_loss: 0.002817  loss_cls: 0.002708  loss_box_reg: 0  loss_rpn_cls: 4.096e-05  loss_rpn_loc: 0    time: 17.0508  last_time: 13.7244  data_time: 0.0037  last_data_time: 0.0036   lr: 0.00024844  \n",
      "\u001b[32m[07/17 19:53:37 d2.engine.hooks]: \u001b[0mOverall training speed: 158 iterations in 0:44:54 (17.0508 s / it)\n",
      "\u001b[32m[07/17 19:53:37 d2.engine.hooks]: \u001b[0mTotal training time: 0:44:56 (0:00:02 on hooks)\n",
      "\u001b[32m[07/17 19:53:37 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   Rebar    | 44           |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[07/17 19:53:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/17 19:53:37 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/17 19:53:37 d2.data.common]: \u001b[0mSerializing 4 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/17 19:53:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/17 19:53:37 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "# Setup configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "# cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # Batch size\n",
    "\n",
    "# Calculate the number of iterations\n",
    "NUM_TRAIN_IMAGES = len(load_coco_json(json_file))  # Number of training images\n",
    "BATCH_SIZE = cfg.SOLVER.IMS_PER_BATCH\n",
    "NUM_EPOCHS = 20  # Number of epochs you want to train\n",
    "\n",
    "# Calculate the number of iterations per epoch\n",
    "iters_per_epoch = NUM_TRAIN_IMAGES // BATCH_SIZE\n",
    "\n",
    "# Set the maximum number of iterations\n",
    "cfg.SOLVER.MAX_ITER = NUM_EPOCHS * iters_per_epoch\n",
    "\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.STEPS = []  # Optionally, add custom learning rate steps\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Set to the number of classes in your dataset\n",
    "\n",
    "# Output directory for saving checkpoints and logs\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/17 21:06:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/17 21:06:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/17 21:06:47 d2.data.common]: \u001b[0mSerializing 4 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/17 21:06:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[07/17 21:06:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 4 batches\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Instances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Perform evaluation\u001b[39;00m\n\u001b[0;32m     35\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m build_detection_test_loader(cfg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_dataset_val\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m \u001b[43minference_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Get evaluation results\u001b[39;00m\n\u001b[0;32m     39\u001b[0m metrics \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\users\\abhishek\\detectron2\\detectron2\\evaluation\\evaluator.py:172\u001b[0m, in \u001b[0;36minference_on_dataset\u001b[1;34m(model, data_loader, evaluator, callbacks)\u001b[0m\n\u001b[0;32m    169\u001b[0m total_compute_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_compute_time\n\u001b[0;32m    171\u001b[0m start_eval_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m--> 172\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m total_eval_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_eval_time\n\u001b[0;32m    175\u001b[0m iters_after_start \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m num_warmup \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_warmup)\n",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36mTwoCoordinateEvaluator.process\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, outputs):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m instances \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m---> 13\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(instances, \u001b[43mInstances\u001b[49m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstances should be of type Instances\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m# Assuming pred_points is a tensor, convert it to numpy array\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         pred_points \u001b[38;5;241m=\u001b[39m instances\u001b[38;5;241m.\u001b[39mpred_points\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Example: Access pred_points\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Instances' is not defined"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import DatasetEvaluator\n",
    "\n",
    "class TwoCoordinateEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.predictions = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.predictions = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for instances in outputs:\n",
    "            assert isinstance(instances, Instances), \"Instances should be of type Instances\"\n",
    "\n",
    "            # Assuming pred_points is a tensor, convert it to numpy array\n",
    "            pred_points = instances.pred_points.cpu().numpy()  # Example: Access pred_points\n",
    "            ground_truth_points = inputs[\"points\"]  # Example: Access ground truth points\n",
    "\n",
    "            self.predictions.append((ground_truth_points, pred_points))\n",
    "\n",
    "    def evaluate(self):\n",
    "        # Calculate metrics based on predictions and ground truth points\n",
    "        metrics = {}\n",
    "        for gt_points, pred_points in self.predictions:\n",
    "            # Example: Calculate distance metrics or accuracy\n",
    "            distances = np.linalg.norm(gt_points - pred_points, axis=1)\n",
    "            mean_distance = np.mean(distances)\n",
    "            metrics['mean_distance'] = mean_distance\n",
    "        return metrics\n",
    "\n",
    "# Setup evaluator\n",
    "evaluator = TwoCoordinateEvaluator(\"my_dataset_val\")\n",
    "\n",
    "# Perform evaluation\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "\n",
    "# Get evaluation results\n",
    "metrics = evaluator.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/17 19:53:37 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/17 19:53:37 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'my_dataset_val' to COCO format ...\n",
      "\u001b[32m[07/17 19:53:37 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'my_dataset_val' to COCO format ...)\n",
      "\u001b[32m[07/17 19:53:37 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot create a polygon from 2 coordinates.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mCOCOEvaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_dataset_val\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m build_detection_test_loader(cfg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_dataset_val\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m inference_on_dataset(trainer\u001b[38;5;241m.\u001b[39mmodel, val_loader, evaluator)\n",
      "File \u001b[1;32mc:\\users\\abhishek\\detectron2\\detectron2\\evaluation\\coco_evaluation.py:142\u001b[0m, in \u001b[0;36mCOCOEvaluator.__init__\u001b[1;34m(self, dataset_name, tasks, distributed, output_dir, max_dets_per_image, use_fast_impl, kpt_oks_sigmas, allow_cached_coco)\u001b[0m\n\u001b[0;32m    140\u001b[0m     cache_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_coco_format.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mjson_file \u001b[38;5;241m=\u001b[39m cache_path\n\u001b[1;32m--> 142\u001b[0m     \u001b[43mconvert_to_coco_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_cached\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_cached_coco\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m json_file \u001b[38;5;241m=\u001b[39m PathManager\u001b[38;5;241m.\u001b[39mget_local_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mjson_file)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mredirect_stdout(io\u001b[38;5;241m.\u001b[39mStringIO()):\n",
      "File \u001b[1;32mc:\\users\\abhishek\\detectron2\\detectron2\\data\\datasets\\coco.py:480\u001b[0m, in \u001b[0;36mconvert_to_coco_json\u001b[1;34m(dataset_name, output_file, allow_cached)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    479\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting annotations of dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to COCO format ...)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 480\u001b[0m     coco_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_coco_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    482\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaching COCO format annotations at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    483\u001b[0m     tmp_file \u001b[38;5;241m=\u001b[39m output_file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\abhishek\\detectron2\\detectron2\\data\\datasets\\coco.py:382\u001b[0m, in \u001b[0;36mconvert_to_coco_dict\u001b[1;34m(dataset_name)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# TODO: check segmentation type: RLE, BinaryMask or Polygon\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(segmentation, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m--> 382\u001b[0m     polygons \u001b[38;5;241m=\u001b[39m \u001b[43mPolygonMasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m     area \u001b[38;5;241m=\u001b[39m polygons\u001b[38;5;241m.\u001b[39marea()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(segmentation, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# RLE\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\abhishek\\detectron2\\detectron2\\structures\\masks.py:309\u001b[0m, in \u001b[0;36mPolygonMasks.__init__\u001b[1;34m(self, polygons)\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot create a polygon from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(polygon)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m coordinates.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m polygons_per_instance\n\u001b[1;32m--> 309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolygons: List[List[np\u001b[38;5;241m.\u001b[39mndarray]] \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocess_polygons\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolygons_per_instance\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpolygons_per_instance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpolygons\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\abhishek\\detectron2\\detectron2\\structures\\masks.py:310\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot create a polygon from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(polygon)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m coordinates.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m polygons_per_instance\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolygons: List[List[np\u001b[38;5;241m.\u001b[39mndarray]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 310\u001b[0m     \u001b[43mprocess_polygons\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolygons_per_instance\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m polygons_per_instance \u001b[38;5;129;01min\u001b[39;00m polygons\n\u001b[0;32m    311\u001b[0m ]\n",
      "File \u001b[1;32mc:\\users\\abhishek\\detectron2\\detectron2\\structures\\masks.py:306\u001b[0m, in \u001b[0;36mPolygonMasks.__init__.<locals>.process_polygons\u001b[1;34m(polygons_per_instance)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m polygon \u001b[38;5;129;01min\u001b[39;00m polygons_per_instance:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(polygon) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(polygon) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m6\u001b[39m:\n\u001b[1;32m--> 306\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot create a polygon from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(polygon)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m coordinates.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m polygons_per_instance\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot create a polygon from 2 coordinates."
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "evaluator = COCOEvaluator(\"my_dataset_val\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata = MetadataCatalog.get(\"my_dataset_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few test images\n",
    "for d in random.sample(load_coco_json(json_file), 3):\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8, instance_mode=ColorMode.IMAGE_BW)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imshow(\"Prediction\", v.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charisma-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
